{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d20ebf",
   "metadata": {},
   "source": [
    "\n",
    "### Kdney identifier\n",
    "\n",
    "1.Problem definition\n",
    "Identify kidney probability based on input provided.\n",
    "\n",
    "2.Data\n",
    "it is stuctured data and have information for each coloumn\n",
    "\n",
    "The six physical characteristics of the urine are: \n",
    "    (1) specific gravity, the density of the urine relative to water; \n",
    "    (2) pH, the negative logarithm of the hydrogen ion; \n",
    "    (3) osmolarity (mOsm), a unit used in biology and medicine but not in\n",
    "        physical chemistry. Osmolarity is proportional to the concentration of\n",
    "        molecules in solution; \n",
    "    (4) conductivity (mMho milliMho). One Mho is one\n",
    "        reciprocal Ohm. Conductivity is proportional to the concentration of charged\n",
    "        ions in solution; \n",
    "    (5) urea concentration in millimoles per litre; and \n",
    "    (6) calcium concentration (CALC) in millimolesllitre.\n",
    "\n",
    "Based on site:-https://www.kaggle.com/datasets/vuppalaadithyasairam/kidney-stone-prediction-based-on-urine-analysis\n",
    "        \n",
    "3. Evaluation\n",
    "    Finding the kidney is their or not\n",
    "4. Feature\n",
    "    Since it is a stuctured data with boolean result. So it is a classification problem\n",
    "5. RandomForestClassifier.XGBoostClassifier, LogisticClassifier\n",
    "\n",
    "6. Tuning the parameter based on result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a7d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbafdd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# conda install lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import eli5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f9f098f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gravity</th>\n",
       "      <th>ph</th>\n",
       "      <th>osmo</th>\n",
       "      <th>cond</th>\n",
       "      <th>urea</th>\n",
       "      <th>calc</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.013</td>\n",
       "      <td>6.19</td>\n",
       "      <td>443</td>\n",
       "      <td>14.8</td>\n",
       "      <td>124</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.025</td>\n",
       "      <td>5.40</td>\n",
       "      <td>703</td>\n",
       "      <td>23.6</td>\n",
       "      <td>394</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.009</td>\n",
       "      <td>6.13</td>\n",
       "      <td>371</td>\n",
       "      <td>24.5</td>\n",
       "      <td>159</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.021</td>\n",
       "      <td>4.91</td>\n",
       "      <td>442</td>\n",
       "      <td>20.8</td>\n",
       "      <td>398</td>\n",
       "      <td>6.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.021</td>\n",
       "      <td>5.53</td>\n",
       "      <td>874</td>\n",
       "      <td>17.8</td>\n",
       "      <td>385</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>1.011</td>\n",
       "      <td>5.21</td>\n",
       "      <td>527</td>\n",
       "      <td>21.4</td>\n",
       "      <td>75</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>1.024</td>\n",
       "      <td>5.53</td>\n",
       "      <td>577</td>\n",
       "      <td>19.7</td>\n",
       "      <td>224</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>411</td>\n",
       "      <td>1.018</td>\n",
       "      <td>6.28</td>\n",
       "      <td>455</td>\n",
       "      <td>22.2</td>\n",
       "      <td>270</td>\n",
       "      <td>7.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>412</td>\n",
       "      <td>1.008</td>\n",
       "      <td>7.12</td>\n",
       "      <td>325</td>\n",
       "      <td>12.6</td>\n",
       "      <td>75</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>413</td>\n",
       "      <td>1.011</td>\n",
       "      <td>6.13</td>\n",
       "      <td>364</td>\n",
       "      <td>9.9</td>\n",
       "      <td>159</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gravity    ph  osmo  cond  urea  calc  target\n",
       "0      0    1.013  6.19   443  14.8   124  1.45       0\n",
       "1      1    1.025  5.40   703  23.6   394  4.18       0\n",
       "2      2    1.009  6.13   371  24.5   159  9.04       0\n",
       "3      3    1.021  4.91   442  20.8   398  6.63       1\n",
       "4      4    1.021  5.53   874  17.8   385  2.21       1\n",
       "..   ...      ...   ...   ...   ...   ...   ...     ...\n",
       "409  409    1.011  5.21   527  21.4    75  1.53       0\n",
       "410  410    1.024  5.53   577  19.7   224  0.77       0\n",
       "411  411    1.018  6.28   455  22.2   270  7.68       1\n",
       "412  412    1.008  7.12   325  12.6    75  1.03       1\n",
       "413  413    1.011  6.13   364   9.9   159  0.27       0\n",
       "\n",
       "[414 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe by importing train dataset\n",
    "train_data = pd.read_csv(\"playground/train.csv\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking datatypes of columns\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b32ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since all columns are having data int so no need for any conversion. \n",
    "# Checking null values\n",
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b5b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get familiar with data by reading and doing cross tab\n",
    "import seaborn as sns\n",
    "corr_matrix = train_data.corr()\n",
    "fig,ax = plt.subplots(figsize=(15,10))\n",
    "ax = sns.heatmap(corr_matrix,\n",
    "            annot=True,\n",
    "                linewidths=0.5,\n",
    "                fmt=\".2f\",\n",
    "                cmap=\"YlGnBu\");\n",
    "bottom,top=ax.get_ylim()\n",
    "ax.set_ylim(bottom+0.5,top-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f1aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting bar graph to undrstand it better\n",
    "# Plot the total target\n",
    "# {deep, muted, pastel, dark, bright, colorblind}\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=\"target\",y=\"gravity\",data=train_data,\n",
    "           label=\"target\",color=\"g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea71a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare kidney true or false based on gravity\n",
    "pd.crosstab(train_data.gravity,train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff98569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare kidney true or false based on calcium\n",
    "pd.crosstab(train_data.calc,train_data.target).plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train_data.calc,train_data.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare kidney true or false based on gravity\n",
    "pd.crosstab(train_data.gravity,train_data.target).plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([train_data.ph],train_data.target).plot(kind=\"hist\",stacked=True)\n",
    "#a, [b, c], rownames=['a'], colnames=['b', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cad6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting servival data based on Embarked,sex\n",
    "cross_tab_data=pd.crosstab(train_data.target,[train_data.gravity,train_data.calc],rownames=['Survived'],colnames=['Embarked','Sex'])\n",
    "cross_tab_data.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "X = train_data.drop(columns=[\"target\"],axis=1)\n",
    "y = train_data[[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2054b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's compare model with as it is value and then convert it into band of ranges for floating value\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb50505",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_val.shape,y_train.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing different model for checking performance\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# put the model in dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(),\n",
    "         \"KNN\": KNeighborsClassifier(),\n",
    "         \"RandomForestClassifier\":RandomForestClassifier(),\n",
    "         \"XGBClassifier\":XGBClassifier()}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creata a function to fit and score the model\n",
    "def fit_and_score(models,X_train,X_val,y_train,y_val):\n",
    "    \"\"\"\n",
    "    Fit and evaluate model\n",
    "    models: It's a dict of model\n",
    "    X_trian: training data(no labels)\n",
    "    X_val: validation data(no labels)\n",
    "    y_train: training data\n",
    "    y_val: validation data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Random seed generator\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Make a dictionary to keep model scores\n",
    "    model_scores = {}\n",
    "    \n",
    "    #Loop through models\n",
    "    for name,model in models.items():\n",
    "        # Fit the model to the data\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        # Evalutate the model and append its score to model_scores\n",
    "        model_scores[name] = model.score(X_val,y_val.values.ravel())\n",
    "    return model_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc875035",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = fit_and_score(models=models,\n",
    "                            X_train=X_train,\n",
    "                            X_val=X_val,\n",
    "                            y_train=y_train,\n",
    "                            y_val=y_val)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b97d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "#Create a hyperparameter grid for LogistincRegression\n",
    "log_reg_grid = {\"C\": np.logspace(-4,4,20),\n",
    "               \"solver\": [\"liblinear\"]}\n",
    "#Create a hyperparameter grid for RandomForestClassifier\n",
    "rf_grid = {\"n_estimators\": np.arange(10,1000,50),\n",
    "          \"max_depth\": [None,3,5,10],\n",
    "          \"min_samples_split\": np.arange(2,20,2),\n",
    "          \"min_samples_leaf\": np.arange(1,20,2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18632faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up logistic regression\n",
    "np.random.seed(42)\n",
    "\n",
    "# Running randomsearchCV for logisticRegression\n",
    "rs_log_reg = RandomizedSearchCV(LogisticRegression(),\n",
    "                               param_distributions=log_reg_grid,\n",
    "                               cv=5,\n",
    "                               n_iter=20,\n",
    "                               verbose=True)\n",
    "#Fit random hyperparameter for logisticRegression\n",
    "rs_log_reg.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5228537",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_log_reg.score(X_val,y_val.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea23d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning for RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "rs_rf=RandomizedSearchCV(RandomForestClassifier(),\n",
    "                        param_distributions=rf_grid,\n",
    "                        cv=5,\n",
    "                        n_iter=20,\n",
    "                        verbose=True)\n",
    "# Fit random model with hyperparameter tuning\n",
    "rs_rf.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05449978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf.score(X_val,y_val.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b52b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"playground/test.csv\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from copy import deepcopy\n",
    " \n",
    "class Splitter:\n",
    "    \n",
    "    \"\"\"\n",
    "    A splitter class which splits the X,y using the split_data funtion with a random stare provided.It yields \n",
    "    X_train,X_val,y_train,y_val train_idx, val_idx in the end.\n",
    "    code from https://www.kaggle.com/code/shoabahamed/playground-s-3-ep-12-eda\"\"\"\n",
    "    \n",
    "    def __init__(self, test_size=0.2, kfold=True, n_splits=5, use_loocv=False):\n",
    "        self.test_size = test_size\n",
    "        self.kfold=kfold\n",
    "        self.n_splits=n_splits\n",
    "        self.use_loocv=use_loocv\n",
    "        \n",
    "    def split_data(self,X,y,random_state):\n",
    "        if self.kfold:\n",
    "            if self.use_loocv:\n",
    "                kf=LeaveOneOut()\n",
    "            else:\n",
    "                kf = StratifiedKFold(n_splits=self.n_splits, random_state=random_state, shuffle=True)\n",
    "                \n",
    "            for train_idx,val_idx in kf.split(X,y):\n",
    "                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                yield X_train, X_val, y_train, y_val, train_idx, val_idx \n",
    "        else:\n",
    "            X_tain, X_val, y_train, y_val = train_test_split(X, y , test_size=self.test_size, random_state=random_state)\n",
    "            yield X_train, X_val, y_train,y_val\n",
    "\n",
    "def evaluate_model(model_name, model_pipeline,_X,_y, features,original_data=None, use_original=False, n_splits=5, random_state_list=[0,5,10],\n",
    "                  use_loocv=False):\n",
    "    len_y=len(_y)\n",
    "    len_states= len(random_state_list)\n",
    "    \n",
    "    oof_preds = np.zeros(len_y*len_states).reshape(len_states,len_y)\n",
    "    scores_train = []\n",
    "    model_pipelines = []\n",
    "    \n",
    "    for index,random_state  in enumerate(random_state_list):\n",
    "        print(\"#\"*25)\n",
    "        print(\"#\"*15, f\"training model {model_name} with seed {random_state}\" )\n",
    "        print(\"#\"*25)\n",
    "        splitter = Splitter(n_splits=n_splits, use_loocv=use_loocv)\n",
    "        splits = 0\n",
    "        \n",
    "        for X_train, X_val, y_train, y_val, train_idx, val_idx in splitter.split_data(_X,_y, random_state):\n",
    "            if use_original:\n",
    "                target = 'target'\n",
    "                X_train = pd.concat([X_train, original_data.drop(target, axis=1)])\n",
    "                y_train = pd.concat([y_train, original_data[target]])\n",
    "                \n",
    "  \n",
    "            model_pipeline.fit(X_train, y_train)\n",
    "            oof_preds[index, val_idx] = model_pipeline.predict_proba(X_val)[:,1].squeeze()\n",
    "            \n",
    "            score_train = roc_auc_score(y_train, model_pipeline.predict_proba(X_train)[:, 1])\n",
    "            scores_train.append(score_train)\n",
    "            model_pipelines.append(deepcopy(model_pipeline))\n",
    "            \n",
    "    oof_preds_mean = oof_preds.mean(axis=0)\n",
    "    \n",
    "    return model_pipelines, oof_preds_mean, np.mean(scores_train), roc_auc_score(_y, oof_preds.mean(axis=0))\n",
    "\n",
    "\n",
    "def predict_test(model_pipeline, X_test):\n",
    "    test_preds = model_pipeline.predict_proba(X_test)[:, 1]\n",
    "    return test_preds\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b40c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ef2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# training data\n",
    "X = train_data.drop(['id','target'], axis=1)\n",
    "y = train_data['target']\n",
    "\n",
    "# add_data = original.copy()\n",
    "features = X.columns.tolist()\n",
    "n_splits = 100\n",
    "random_states = [0]\n",
    "\n",
    "classifiers = {\n",
    "    \"lr\" : LogisticRegression(random_state=0),\n",
    "    \"rf\" : RandomForestClassifier(random_state=0),\n",
    "    \"knn\" : KNeighborsClassifier(),\n",
    "    'svc' : SVC(probability=True, random_state=0),\n",
    "    'et' : ExtraTreesClassifier(random_state=0),\n",
    "    'Hgb' : HistGradientBoostingClassifier(random_state=0),\n",
    "    'ada' : AdaBoostClassifier(random_state=0),\n",
    "    \"gb\" : GradientBoostingClassifier(random_state=0),\n",
    "    \"xgb\" : XGBClassifier(random_state=0)\n",
    "#     \"lgbm\" : LGBMClassifier(random_state=0),\n",
    "    \"cat\" : CatBoostClassifier(silent=True,random_state=0)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dfad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_log = pd.DataFrame(columns=['model_name', 'train score', \"valid_score\"], index=range(len(classifiers) * 2))\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3dfa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "for model_name, model in classifiers.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"scale\", StandardScaler()),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    _pipes, _oof_preds, _train_score, _oof_score = evaluate_model(f\"pipeline_{model_name}\", pipe, X, y, features,\n",
    "                                             use_original=False,\n",
    "                                             n_splits=n_splits, random_state_list=random_states, use_loocv=False)\n",
    "    \n",
    "    models_log.loc[index] = [model_name, _train_score, _oof_score]\n",
    "    index += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c78d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_log[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_log[0:9].to_csv(\"Baseline_scores_correct.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac676152",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_log[0:9].sort_values(\"valid_score\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1061a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_csv(_model,_train,_test):\n",
    "    X_train = _train.drop(['id','target'],axis=1)\n",
    "    y_train = _train['target']\n",
    "    X_test = _test.drop('id',axis=1)\n",
    "    \n",
    "    _model.fit(X_train,y_train)\n",
    "    \n",
    "    preds = _model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['id'] = _test[\"id\"]\n",
    "    df['target'] = preds\n",
    "    \n",
    "    return df\n",
    "\n",
    "pipe_rf = Pipeline(steps=[\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "pipe_svc = Pipeline(steps=[\n",
    "        ('scale',StandardScaler()),\n",
    "        ('model',SVC(probability=True, random_state=0))\n",
    "])\n",
    "\n",
    "rf_df =  submission_csv(pipe_rf, train_data,test_data)\n",
    "svc_df = submission_csv(pipe_svc, train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c3ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df.to_csv(\"random_forest_baseline_score.csv\", index=False)\n",
    "svc_df.to_csv(\"svc_baseline_score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d08a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(models,X_test,title=\"\"):\n",
    "    \"\"\"\n",
    "    Plots features importance given models and train set\"\"\"\n",
    "    \n",
    "    features = X_test.columns.tolist()\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for model in models:\n",
    "        _df = pd.DataFrame()\n",
    "        _df['importance'] = model.feature_importances_\n",
    "        _df = _df.sort_values(by=\"importance\",ascending=False)\n",
    "        feature_importance = pd.concat([feature_importance,_df])\n",
    "        \n",
    "    feature_importance = feature_importance.sort_values(\"importance\",ascending=False)\n",
    "    plt.figure(figsize=(16,10))\n",
    "    ax= sns.barplot(x=\"importance\",y='features', data=feature_importance,color=\"skyblue\",errorbar='sd')\n",
    "    \n",
    "    for i in ax.containers:\n",
    "        ax.bar_label(i,)\n",
    "        \n",
    "    plt.xlabel('Importance', fontsize=14)\n",
    "    plt.ylabel('Feature', fontsize=14)\n",
    "    plt.title(f\"{title} Feature Importance\", fontsize=18)\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.show()\n",
    "    \n",
    "    return feaure_importance\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf.fit(X,y)\n",
    "pipe_rf\n",
    "\n",
    "importance = pd.Series(pipe_rf[-1].feature_importances_, index=X.columns.tolist()).sort_values(ascending=False)\n",
    "ax = sns.barplot(x=importance.values, y=importance.index)\n",
    "plt.tight_layout()\n",
    "# importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf[-1].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb613b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "result = permutation_importance(\n",
    "    pipe_rf[-1], X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "forest_importances = pd.Series(result.importances_mean, index=feature_names)\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation on full model\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4bc4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perm importance in random forest\n",
    "perm = PermutationImportance(pipe_rf, scoring='roc_auc', cv=10, n_iter=20).fit(X, y)\n",
    "eli5.show_weights(perm, feature_names=X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b69098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5.sklearn import PermutationImportance\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c06f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
